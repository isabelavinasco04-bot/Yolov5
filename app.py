import streamlit as st
import cv2
import numpy as np
from PIL import Image
from keras.models import load_model
from gtts import gTTS
import io
import platform

# ğŸŒ¸ ConfiguraciÃ³n inicial
st.set_page_config(page_title="Reconocimiento de Gestos âœ¨", page_icon="ğŸ’–", layout="centered")

# ğŸ’… Estilos personalizados
st.markdown("""
    <style>
    .main {
        background-color: #ffeef8;
        color: #3d2a42;
        font-family: 'Poppins', sans-serif;
    }
    h1, h2, h3, h4 {
        text-align: center;
        color: #ff69b4;
        font-weight: 700;
    }
    .stButton>button {
        background-color: #ff9fd2;
        color: white;
        border-radius: 12px;
        border: none;
        font-weight: 600;
        padding: 0.6rem 1.2rem;
        transition: all 0.3s ease-in-out;
    }
    .stButton>button:hover {
        background-color: #ff7cc7;
        transform: scale(1.05);
    }
    .result-box {
        background-color: #ffd6eb;
        padding: 20px;
        border-radius: 20px;
        box-shadow: 0px 4px 15px rgba(255, 105, 180, 0.3);
        text-align: center;
        margin-top: 20px;
    }
    </style>
""", unsafe_allow_html=True)

# ğŸ§  Mostrar versiÃ³n
st.write("ğŸ§© Python version:", platform.python_version())

# ğŸ“¦ Cargar modelo
model = load_model('keras_model.h5')
data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)

# ğŸ©· Encabezado
st.title("ğŸ’– Reconocimiento de Gestos en Tiempo Real ğŸ’…")
st.markdown("Haz tu gesto frente a la cÃ¡mara y deja que la IA adivine lo que haces âœ¨")

# ğŸ“¸ Imagen decorativa
st.image("OIG5.jpg", width=350, caption="ğŸ’« Â¡Haz tu gesto frente a la cÃ¡mara!")

# ğŸ§­ Sidebar con info
with st.sidebar:
    st.header("ğŸª GuÃ­a rÃ¡pida")
    st.write("""
    1ï¸âƒ£ AsegÃºrate de tener buena iluminaciÃ³n.  
    2ï¸âƒ£ Coloca tu mano o gesto frente a la cÃ¡mara.  
    3ï¸âƒ£ Espera unos segundos a que la app detecte el movimiento.  
    4ï¸âƒ£ Â¡Disfruta del resultado con voz y color! ğŸ’•
    """)

# ğŸ“· Captura de cÃ¡mara
img_file_buffer = st.camera_input("ğŸ“¸ Toma una foto")

if img_file_buffer is not None:
    img = Image.open(img_file_buffer)
    img = img.resize((224, 224))
    img_array = np.array(img)

    normalized_image_array = (img_array.astype(np.float32) / 127.0) - 1
    data[0] = normalized_image_array

    # ğŸ”® PredicciÃ³n
    prediction = model.predict(data)
    labels = ["Izquierda ğŸ‘ˆ", "Arriba ğŸ‘†", "Derecha ğŸ‘‰", "Abajo ğŸ‘‡"]

    # ğŸ¯ Mostrar resultados
    max_idx = np.argmax(prediction[0])
    gesture = labels[max_idx]
    confidence = float(prediction[0][max_idx])

    st.markdown(f"""
    <div class="result-box">
        <h2>ğŸ€ Gesto detectado:</h2>
        <h1>{gesture}</h1>
        <p style='font-size:18px;'>Confianza: {confidence:.2%}</p>
    </div>
    """, unsafe_allow_html=True)

    # ğŸŒˆ Mostrar barras de probabilidad
    st.markdown("### âœ¨ Probabilidades")
    for i, label in enumerate(labels):
        st.progress(float(prediction[0][i]))
        st.write(f"**{label}:** {prediction[0][i]:.2%}")

    # ğŸ”Š Generar audio del resultado
    try:
        tts_text = f"El gesto detectado es {gesture.replace('ğŸ‘ˆ','izquierda').replace('ğŸ‘†','arriba').replace('ğŸ‘‰','derecha').replace('ğŸ‘‡','abajo')}"
        tts = gTTS(text=tts_text, lang='es')
        audio_bytes = io.BytesIO()
        tts.write_to_fp(audio_bytes)
        audio_bytes.seek(0)
        st.audio(audio_bytes, format="audio/mp3")
    except Exception as e:
        st.warning(f"No se pudo reproducir el audio: {e}")

